{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from baselines.common import set_global_seeds, tf_util as U\n",
    "from baselines import bench\n",
    "import gym, logging\n",
    "import roboschool\n",
    "from baselines import logger\n",
    "from baselines.ppo1 import mlp_policy, pposgd_simple\n",
    "from base_line_model.mlp import MlpPolicy_new\n",
    "from base_line_model.PPO_agent import learning_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to /tmp/openai-2018-04-20-03-19-08-986306\n"
     ]
    }
   ],
   "source": [
    "seed = 1\n",
    "logger.configure()\n",
    "U.make_session(num_cpu=16).__enter__()\n",
    "set_global_seeds(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# set up agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-04-20 03:19:09,014] Making new env: RoboschoolHopper-v1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.client.session.Session object at 0x7fb98ff30128>\n"
     ]
    }
   ],
   "source": [
    "env2 = gym.make('RoboschoolHopper-v1')\n",
    "env2 = bench.Monitor(env2, logger.get_dir(),allow_early_resets=True)\n",
    "env2.seed(seed)\n",
    "gym.logger.setLevel(logging.WARN)\n",
    "class pargm(object):\n",
    "    def __init__(self):\n",
    "        self.timesteps_per_actorbatch = 25000#25000 # timesteps per actor per update\n",
    "        self.clip_param = 0.2 \n",
    "        self.entcoeff = 0.0 # clipping parameter epsilon, entropy coeff\n",
    "        self.optim_epochs = 10 \n",
    "        self.optim_stepsize = 3e-4\n",
    "        self.optim_batchsize = 64# optimization hypers\n",
    "        self.gamma = 0.99\n",
    "        self.lam = 0.95 # advantage estimation\n",
    "        self.max_timesteps=10e4#1e10 \n",
    "        self.max_episodes=0 \n",
    "        self.max_iters=0 \n",
    "        self.max_seconds=0  # time constraint\n",
    "        self.callback=None # you can do anything in the callback, since it takes locals(), globals()\n",
    "        self.adam_epsilon=1e-5\n",
    "        self.schedule='linear' # annealing for stepsize parameters (epsilon and adam)\n",
    "\n",
    "\n",
    "def policy_fn(name, ob_space, ac_space):\n",
    "        return MlpPolicy_new(name=name, ob_space=ob_space, ac_space=ac_space,\n",
    "            hid_size=64, num_hid_layers=2)\n",
    "    \n",
    "parg = pargm()\n",
    "agent2 = learning_agent('pi2', env2, policy_fn, parg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** Iteration 0 ************\n",
      "Optimizing...\n",
      "     pol_surr |    pol_entpen |       vf_loss |            kl |           ent\n",
      "   -0.0148581 |           0.0 |       37.7197 |    0.00731822 |       4.19116\n",
      "   -0.0201327 |           0.0 |       11.0771 |     0.0134314 |       4.12614\n",
      "   -0.0210902 |           0.0 |       10.0607 |     0.0148613 |       4.11216\n",
      "   -0.0211594 |           0.0 |       9.81106 |     0.0150585 |       4.11231\n",
      "   -0.0215619 |           0.0 |       9.65636 |     0.0153284 |        4.1105\n",
      "   -0.0215118 |           0.0 |       9.55002 |     0.0156136 |       4.10882\n",
      "   -0.0216761 |           0.0 |       9.48059 |     0.0153879 |       4.11452\n",
      "   -0.0214674 |           0.0 |       9.43146 |      0.015769 |       4.11295\n",
      "   -0.0220529 |           0.0 |       9.36947 |     0.0150825 |       4.11352\n",
      "   -0.0226045 |           0.0 |       9.34058 |      0.015584 |        4.1135\n",
      "Evaluating losses...\n",
      "   -0.0230899 |             0 |        9.3273 |     0.0148194 |       4.11679\n",
      "------------------------------\n",
      "| EpLenMean       | 11       |\n",
      "| EpRewMean       | 13.6     |\n",
      "| EpThisIter      | 2323     |\n",
      "| EpisodesSoFar   | 2323     |\n",
      "| TimeElapsed     | 49.7     |\n",
      "| TimestepsSoFar  | 24998    |\n",
      "| ev_tdlam_before | 0.0499   |\n",
      "| loss_ent        | 4.12     |\n",
      "| loss_kl         | 0.0148   |\n",
      "| loss_pol_entpen | 0        |\n",
      "| loss_pol_surr   | -0.0231  |\n",
      "| loss_vf_loss    | 9.33     |\n",
      "------------------------------\n",
      "********** Iteration 1 ************\n",
      "Optimizing...\n",
      "     pol_surr |    pol_entpen |       vf_loss |            kl |           ent\n",
      "   -0.0202863 |           0.0 |       6.65751 |    0.00697707 |       4.02611\n",
      "   -0.0257985 |           0.0 |       6.35134 |     0.0119344 |       3.96556\n",
      "   -0.0264052 |           0.0 |        6.3042 |     0.0124526 |       3.96225\n",
      "   -0.0265142 |           0.0 |       6.27399 |     0.0125069 |       3.96191\n",
      "   -0.0263307 |           0.0 |       6.25282 |     0.0125721 |       3.96235\n",
      "   -0.0265607 |           0.0 |       6.22896 |     0.0126647 |       3.96198\n",
      "   -0.0268884 |           0.0 |       6.21192 |      0.012719 |       3.95956\n",
      "   -0.0268514 |           0.0 |       6.19158 |     0.0125902 |       3.96147\n",
      "    -0.026758 |           0.0 |       6.18472 |     0.0128503 |       3.96188\n",
      "   -0.0273773 |           0.0 |       6.17221 |     0.0127842 |       3.96229\n",
      "Evaluating losses...\n",
      "   -0.0271786 |             0 |       6.14269 |     0.0132004 |       3.96183\n",
      "------------------------------\n",
      "| EpLenMean       | 10.7     |\n",
      "| EpRewMean       | 15.3     |\n",
      "| EpThisIter      | 2552     |\n",
      "| EpisodesSoFar   | 4875     |\n",
      "| TimeElapsed     | 97.7     |\n",
      "| TimestepsSoFar  | 49993    |\n",
      "| ev_tdlam_before | 0.749    |\n",
      "| loss_ent        | 3.96     |\n",
      "| loss_kl         | 0.0132   |\n",
      "| loss_pol_entpen | 0        |\n",
      "| loss_pol_surr   | -0.0272  |\n",
      "| loss_vf_loss    | 6.14     |\n",
      "------------------------------\n",
      "********** Iteration 2 ************\n",
      "Optimizing...\n",
      "     pol_surr |    pol_entpen |       vf_loss |            kl |           ent\n",
      "   -0.0156974 |           0.0 |       5.25369 |    0.00356258 |       3.88934\n",
      "    -0.019399 |           0.0 |       5.18119 |    0.00572807 |       3.85194\n",
      "   -0.0194096 |           0.0 |       5.16145 |    0.00592121 |       3.84882\n",
      "   -0.0196307 |           0.0 |       5.14941 |    0.00596425 |       3.84932\n",
      "   -0.0195341 |           0.0 |       5.13055 |    0.00589436 |       3.84882\n",
      "   -0.0203645 |           0.0 |       5.11639 |    0.00613638 |       3.84718\n",
      "   -0.0202144 |           0.0 |       5.11038 |    0.00615621 |       3.84764\n",
      "   -0.0200638 |           0.0 |       5.09533 |    0.00605994 |       3.84918\n",
      "   -0.0203635 |           0.0 |        5.0882 |    0.00614629 |       3.84842\n",
      "   -0.0203528 |           0.0 |        5.0812 |    0.00613882 |       3.84781\n",
      "Evaluating losses...\n",
      "   -0.0205692 |             0 |       5.06791 |    0.00643983 |       3.84977\n",
      "------------------------------\n",
      "| EpLenMean       | 9.78     |\n",
      "| EpRewMean       | 16.5     |\n",
      "| EpThisIter      | 2609     |\n",
      "| EpisodesSoFar   | 7484     |\n",
      "| TimeElapsed     | 144      |\n",
      "| TimestepsSoFar  | 74997    |\n",
      "| ev_tdlam_before | 0.841    |\n",
      "| loss_ent        | 3.85     |\n",
      "| loss_kl         | 0.00644  |\n",
      "| loss_pol_entpen | 0        |\n",
      "| loss_pol_surr   | -0.0206  |\n",
      "| loss_vf_loss    | 5.07     |\n",
      "------------------------------\n",
      "********** Iteration 3 ************\n",
      "Optimizing...\n",
      "     pol_surr |    pol_entpen |       vf_loss |            kl |           ent\n",
      "  -0.00778478 |           0.0 |       4.56672 |   0.000904903 |       3.81272\n",
      "  -0.00910407 |           0.0 |       4.53993 |    0.00145926 |       3.79294\n",
      "  -0.00929668 |           0.0 |       4.53074 |    0.00154119 |       3.79083\n",
      "   -0.0098992 |           0.0 |       4.52311 |    0.00150569 |       3.79146\n",
      "  -0.00967077 |           0.0 |       4.51066 |    0.00152489 |       3.79141\n",
      "  -0.00958995 |           0.0 |       4.50717 |     0.0015349 |       3.79119\n",
      "  -0.00968606 |           0.0 |       4.50264 |     0.0015372 |        3.7912\n",
      "  -0.00996496 |           0.0 |       4.49028 |    0.00151875 |       3.79136\n",
      "  -0.00977733 |           0.0 |       4.48646 |    0.00151721 |       3.79164\n",
      "   -0.0102148 |           0.0 |       4.48705 |    0.00152416 |       3.79188\n",
      "Evaluating losses...\n",
      "   -0.0100271 |             0 |       4.47587 |    0.00157805 |       3.79187\n",
      "------------------------------\n",
      "| EpLenMean       | 9.28     |\n",
      "| EpRewMean       | 17.2     |\n",
      "| EpThisIter      | 2605     |\n",
      "| EpisodesSoFar   | 10089    |\n",
      "| TimeElapsed     | 193      |\n",
      "| TimestepsSoFar  | 99996    |\n",
      "| ev_tdlam_before | 0.869    |\n",
      "| loss_ent        | 3.79     |\n",
      "| loss_kl         | 0.00158  |\n",
      "| loss_pol_entpen | 0        |\n",
      "| loss_pol_surr   | -0.01    |\n",
      "| loss_vf_loss    | 4.48     |\n",
      "------------------------------\n",
      "********** Iteration 4 ************\n",
      "Optimizing...\n",
      "     pol_surr |    pol_entpen |       vf_loss |            kl |           ent\n",
      "  0.000100971 |           0.0 |       4.18785 |   1.27615e-07 |       3.79187\n",
      "  0.000121036 |           0.0 |       4.18362 |   1.56806e-07 |       3.79187\n",
      " -5.83364e-05 |           0.0 |       4.18729 |   1.42363e-07 |       3.79187\n",
      " -3.63557e-05 |           0.0 |        4.1805 |   1.03926e-08 |       3.79187\n",
      "  0.000398393 |           0.0 |       4.18341 |   1.72395e-07 |       3.79187\n",
      "  0.000353746 |           0.0 |       4.17991 |   1.45038e-07 |       3.79187\n",
      "   0.00011306 |           0.0 |       4.18419 |   6.66349e-08 |       3.79187\n",
      " -6.15089e-05 |           0.0 |       4.18379 |   1.63989e-07 |       3.79187\n",
      " -0.000149138 |           0.0 |       4.18207 |   1.44121e-07 |       3.79187\n",
      " -0.000164361 |           0.0 |       4.17999 |    8.2071e-08 |       3.79187\n",
      "Evaluating losses...\n",
      " -8.58052e-05 |             0 |       4.17868 |   5.96046e-08 |       3.79186\n",
      "-------------------------------\n",
      "| EpLenMean       | 10        |\n",
      "| EpRewMean       | 17.7      |\n",
      "| EpThisIter      | 2621      |\n",
      "| EpisodesSoFar   | 12710     |\n",
      "| TimeElapsed     | 240       |\n",
      "| TimestepsSoFar  | 124996    |\n",
      "| ev_tdlam_before | 0.886     |\n",
      "| loss_ent        | 3.79      |\n",
      "| loss_kl         | 5.96e-08  |\n",
      "| loss_pol_entpen | 0         |\n",
      "| loss_pol_surr   | -8.58e-05 |\n",
      "| loss_vf_loss    | 4.18      |\n",
      "-------------------------------\n"
     ]
    }
   ],
   "source": [
    "agent2.learn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.465061497176066\n",
      "28.017580000843736\n",
      "32.81638739875635\n",
      "38.022979164357814\n",
      "28.100173767177328\n",
      "27.09531361210538\n",
      "30.17301668100699\n",
      "28.748361785235463\n",
      "29.95723484088521\n",
      "28.024001243665403\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"RoboschoolHopper-v1\")\n",
    "for i in range(10):\n",
    "    score = 0\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    itr = 0\n",
    "    do = False\n",
    "    while done == False:   \n",
    "        a = agent2.action_ev(obs)\n",
    "        obs, r, done, _ = env.step(a)\n",
    "        if done:\n",
    "            do = True\n",
    "\n",
    "        score += r\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "agent2.save_data('hopper_mem')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#agent2.restore('hopper_mem')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
